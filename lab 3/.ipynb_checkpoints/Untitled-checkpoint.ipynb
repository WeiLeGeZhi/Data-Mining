{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c7faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import time\n",
    "from deepod.models.dsvdd import DeepSVDD\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler, QuantileTransformer, PowerTransformer, Normalizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87b4e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HUAWEI\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iForest - AUROC: 0.7723691489901032\n",
      "iForest - AUPRC: 0.3522226460423786\n",
      "iForest - Time: 4.514748811721802\n",
      "LOF - AUROC: 0.5613005113863193\n",
      "LOF - AUPRC: 0.20389021714464825\n",
      "LOF - Time: 24.905144453048706\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./NB15/train_data.csv\")\n",
    "test_data = pd.read_csv(\"./NB15/test_data.csv\")\n",
    "\n",
    "X_train = train_data.drop(columns=['attack_cat','label'])\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop(columns=['attack_cat','label'])\n",
    "y_test = test_data['label']\n",
    "\n",
    "X_train.replace({True: 1, False: 0}, inplace=True)\n",
    "X_test.replace({True: 1, False: 0}, inplace=True)\n",
    "\n",
    "columns_to_normalize = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss',\n",
    "                        'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt',\n",
    "                        'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len', 'ct_srv_src',\n",
    "                        'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
    "                        'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst',\n",
    "                        'is_sm_ips_ports']\n",
    "\n",
    "scaler = PowerTransformer()\n",
    "\n",
    "X_train[columns_to_normalize] = scaler.fit_transform(X_train[columns_to_normalize])\n",
    "X_test[columns_to_normalize] = scaler.transform(X_test[columns_to_normalize])\n",
    "\n",
    "# X_train_normalized = scaler.fit_transform(X_train)\n",
    "# X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# 创建 iForest 模型并训练\n",
    "start_time = time.time()\n",
    "iforest = IsolationForest(contamination=0.2)\n",
    "iforest.fit(X_train)\n",
    "iforest_time = time.time() - start_time\n",
    "\n",
    "# 使用 iForest 检测异常值并计算评估指标\n",
    "iforest_scores = iforest.decision_function(X_test)\n",
    "iforest_auc = roc_auc_score(y_test, -iforest_scores)\n",
    "iforest_auprc = average_precision_score(y_test, -iforest_scores)\n",
    "\n",
    "# 创建 LOF 模型并训练\n",
    "start_time = time.time()\n",
    "lof = LocalOutlierFactor(contamination=0.2)\n",
    "lof.fit(X_train)\n",
    "lof_time = time.time() - start_time\n",
    "\n",
    "# 使用 LOF 检测异常值并计算评估指标\n",
    "lof_scores = -lof.fit_predict(X_test)\n",
    "lof_auc = roc_auc_score(y_test, lof_scores)\n",
    "lof_auprc = average_precision_score(y_test, lof_scores)\n",
    "\n",
    "print(\"iForest - AUROC:\", iforest_auc)\n",
    "print(\"iForest - AUPRC:\", iforest_auprc)\n",
    "print(\"iForest - Time:\", iforest_time)\n",
    "print(\"LOF - AUROC:\", lof_auc)\n",
    "print(\"LOF - AUPRC:\", lof_auprc)\n",
    "print(\"LOF - Time:\", lof_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818eeb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 173403.7567\n",
      "Epoch [11/100], Loss: 156.0690\n",
      "Epoch [21/100], Loss: 147.9480\n",
      "Epoch [31/100], Loss: 69.1753\n",
      "Epoch [41/100], Loss: 57.4499\n",
      "Epoch [51/100], Loss: 89.2137\n",
      "Epoch [61/100], Loss: 70.4890\n",
      "Epoch [71/100], Loss: 52.5665\n",
      "Epoch [81/100], Loss: 91.1125\n",
      "Epoch [91/100], Loss: 52.3805\n",
      "DSVDD - AUROC: 0.49870464081200283\n",
      "DSVDD - AUPRC: 0.17851105887810353\n",
      "DSVDD - Time: 485.87465953826904\n"
     ]
    }
   ],
   "source": [
    "class DeepSVDDModel(nn.Module):\n",
    "    def __init__(self, input_dim, rep_dim):\n",
    "        super(DeepSVDDModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, rep_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(rep_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return z, x_recon\n",
    "\n",
    "class DeepSVDD:\n",
    "    def __init__(self, rep_dim=128, lr=1e-3, device='cpu'):\n",
    "        self.rep_dim = rep_dim\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "\n",
    "    def fit(self, X_train):\n",
    "        train_loader = DataLoader(TensorDataset(torch.Tensor(X_train)), batch_size=64, shuffle=True)\n",
    "        self.model = DeepSVDDModel(input_dim=X_train.shape[1], rep_dim=self.rep_dim).to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(100):\n",
    "            epoch_loss = 0.0\n",
    "            for batch_x in train_loader:\n",
    "                batch_x = batch_x[0].to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                _, x_recon = self.model(batch_x)\n",
    "                loss = criterion(batch_x, x_recon)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/100], Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        # print(f\"Training Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.Tensor(X).to(self.device)\n",
    "            z, _ = self.model(X_tensor)\n",
    "            dist = torch.sum((z - torch.mean(z, dim=0)) ** 2, dim=1)\n",
    "        return dist.cpu().numpy()\n",
    "\n",
    "\n",
    "X_train_np = X_train.values\n",
    "X_test_np = X_test.values\n",
    "y_train_np = y_train.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# 训练 DeepSVDD 模型\n",
    "start_time = time.time()\n",
    "deep_svdd = DeepSVDD(rep_dim=32, lr=1e-3, device='cpu')\n",
    "deep_svdd.fit(X_train_np)\n",
    "dsvdd_time = time.time() - start_time\n",
    "\n",
    "# 在测试集上计算异常分数\n",
    "scores = deep_svdd.decision_function(X_test_np)\n",
    "\n",
    "print(\"DSVDD - AUROC:\", roc_auc_score(y_test_np, y_score=-scores))  # 注意要将分数取负号\n",
    "print(\"DSVDD - AUPRC:\", average_precision_score(y_test_np, y_score=-scores))\n",
    "print(\"DSVDD - Time:\", dsvdd_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce72178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
